{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "You can choose to do one, two or all three activities depending on how confident you feel.   \n",
    "You do not have to use Google Scholar. You are allowed to use any academic search engine or scrape from other sources if you find something more appropriate.\n",
    "\n",
    "## 1. Web scrape a list of all of my publications since 2015 (e.g. [search link]('https://scholar.google.com/citations?user=ETIBghkAAAAJ&hl=en')) \n",
    "\n",
    "## 2. Scrape a list of all the co-authors of my papers including a numerical value that corresponds to the number of co-authorships.\n",
    "\n",
    "## 3. Scrape the abstract/keywords from these papers.\n",
    "\n",
    "Caveat: there are numerous people with my name and not all of my publications are at the same institution so this search may not be as easy as it sounds! \n",
    "\n",
    "You may also find yourself blocked by captchas and such, in which case you might have to find workarounds. \n",
    "\n",
    "**Get Data to work with**\n",
    "1. Read in the data\n",
    "2. get data into a data frame from the table - like did with cfl data\n",
    "3. strip out anything before 2015\n",
    "4. need html links to be able to dig into each of those articles and then do more scraping from there\n",
    "\n",
    "**Get coauthors**\n",
    "1. All listed with google scholar in the table so just get it from there\n",
    "2. strip out all the S McGraths\n",
    "\n",
    "**Scrape abstract from paper**\n",
    "1. Open link to papers\n",
    "2. see if they are in a similar format to get the abstract\n",
    "3. get abstract out and keywords\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://scholar.google.com/citations?user=ETIBghkAAAAJ&hl=en'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_table_headers(soup):\n",
    "    table_head = soup.find_all('th')\n",
    "    col_headers = []\n",
    "    for th in table_head:\n",
    "        col_headers.append(th.text)\n",
    "\n",
    "    return col_headers\n",
    "\n",
    "col_headers = get_table_headers(soup)\n",
    "\n",
    "def get_table_data(soup):\n",
    "    table_body = soup.find('tbody', attrs={'id': 'gsc_a_b'})\n",
    "    rows = table_body.find_all('tr')\n",
    "    \n",
    "    data = []\n",
    "    for row in rows:\n",
    "        row_data = []\n",
    "\n",
    "        info_cols = row.find_all('td', attrs={'class': 'gsc_a_t'})\n",
    "        for info in info_cols:\n",
    "            # get link element\n",
    "            link = 'https://scholar.google.com' + info.findChild('a').get('data-href')\n",
    "            #get title\n",
    "            title = info.findChild('a').get_text()\n",
    "            # get authors \n",
    "            author_info = info.findChild('div').get_text()\n",
    "            # add link and author to row\n",
    "            row_data.extend([title, link, author_info])\n",
    "\n",
    "        year_cols = row.find_all('td', attrs={'class': 'gsc_a_y'})\n",
    "        for year in year_cols:\n",
    "            row_data.append(year.get_text())\n",
    "        #add row to data\n",
    "        data.append(row_data)\n",
    "    return data\n",
    "\n",
    "table_data = get_table_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table_data, columns=['title', 'url', 'authors', 'year'])\n",
    "\n",
    "#filter results before 2015\n",
    "data = df.loc[df['year'] >= '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_soups(data, col_id):\n",
    "    page_soups = []\n",
    "    for index, row in data.iterrows():\n",
    "        page = requests.get(row[col_id])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        page_soups.append(soup)\n",
    "    return page_soups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soups = get_page_soups(data, 'url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                title  \\\n",
       "10  Breaking the workflow: Design heuristics to su...   \n",
       "9       DESIGNING AND DEVELOPING USER-CENTRED SYSTEMS   \n",
       "11  The Rough Mile: a Design Template for Locative...   \n",
       "5   The Rough Mile: Testing a framework of immersi...   \n",
       "6   The user experience of mobile music making: An...   \n",
       "\n",
       "                                                  url  \\\n",
       "10  https://scholar.google.com/citations?view_op=v...   \n",
       "9   https://scholar.google.com/citations?view_op=v...   \n",
       "11  https://scholar.google.com/citations?view_op=v...   \n",
       "5   https://scholar.google.com/citations?view_op=v...   \n",
       "6   https://scholar.google.com/citations?view_op=v...   \n",
       "\n",
       "                                              authors  year  \\\n",
       "10                                          S McGrath  2020   \n",
       "9                                           S McGrath  2018   \n",
       "11       A Hazzard, J Spence, C Greenhalgh, S McGrath  2018   \n",
       "5   J Spence, A Hazzard, S McGrath, C Greenhalgh, ...  2017   \n",
       "6                                   S McGrath, S Love  2017   \n",
       "\n",
       "                                            abstracts  \n",
       "10  The investigation that follows presents the re...  \n",
       "9   Our work explores the implications for the des...  \n",
       "11  The rapid development of mobile devices, netwo...  \n",
       "5   We present our case study on gifting digital m...  \n",
       "6   The research herein describes the investigatio...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>authors</th>\n      <th>year</th>\n      <th>abstracts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Breaking the workflow: Design heuristics to su...</td>\n      <td>https://scholar.google.com/citations?view_op=v...</td>\n      <td>S McGrath</td>\n      <td>2020</td>\n      <td>The investigation that follows presents the re...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DESIGNING AND DEVELOPING USER-CENTRED SYSTEMS</td>\n      <td>https://scholar.google.com/citations?view_op=v...</td>\n      <td>S McGrath</td>\n      <td>2018</td>\n      <td>Our work explores the implications for the des...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>The Rough Mile: a Design Template for Locative...</td>\n      <td>https://scholar.google.com/citations?view_op=v...</td>\n      <td>A Hazzard, J Spence, C Greenhalgh, S McGrath</td>\n      <td>2018</td>\n      <td>The rapid development of mobile devices, netwo...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The Rough Mile: Testing a framework of immersi...</td>\n      <td>https://scholar.google.com/citations?view_op=v...</td>\n      <td>J Spence, A Hazzard, S McGrath, C Greenhalgh, ...</td>\n      <td>2017</td>\n      <td>We present our case study on gifting digital m...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The user experience of mobile music making: An...</td>\n      <td>https://scholar.google.com/citations?view_op=v...</td>\n      <td>S McGrath, S Love</td>\n      <td>2017</td>\n      <td>The research herein describes the investigatio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "print(len(page_soups))\n",
    "\n",
    "def get_abstracts(page_soups):\n",
    "    abstracts = []\n",
    "    for soup in page_soups:\n",
    "        abstract = soup.find('div', attrs={'id': 'gsc_vcd_descr'}).get_text()\n",
    "        if abstract is None:\n",
    "            print('no abstract found')\n",
    "        abstracts.append(abstract)\n",
    "    return abstracts\n",
    "        \n",
    "abstracts = get_abstracts(page_soups)\n",
    "\n",
    "abstracts_df = pd.DataFrame(abstracts, columns=['abstracts'])\n",
    "\n",
    "df = data.assign(abstracts=abstracts_df)\n",
    "#sort newest to oldest\n",
    "df = df.sort_values('year', axis=0, ascending=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\hugho\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'s mcgrath': 13,\n",
       " 'a hazzard': 6,\n",
       " 'j spenc': 3,\n",
       " 'c greenhalgh': 4,\n",
       " 's benford': 7,\n",
       " 's love': 1,\n",
       " 'ap mcpherson': 1,\n",
       " 'a chamberlain': 5,\n",
       " 'sa mcgrath': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df_authors = df['authors'].tolist()\n",
    "\n",
    "def split_authors(authors):\n",
    "    author_list = []\n",
    "    for author in authors:\n",
    "        split_authors = author.split(',')\n",
    "        author_list.extend(split_authors)\n",
    "    for i, author in enumerate(author_list):\n",
    "        author_list[i] = author.strip().lower()\n",
    "    return author_list\n",
    "\n",
    "author_list = split_authors(df_authors)\n",
    "\n",
    "def get_word_freq(content):\n",
    "   ps = PorterStemmer()\n",
    "   word_frequencies = {}\n",
    "   for tok in content:\n",
    "      tok = ps.stem(tok)\n",
    "      if tok not in word_frequencies.keys():\n",
    "         word_frequencies[tok] = 1\n",
    "      else:\n",
    "         word_frequencies[tok] += 1\n",
    "   return word_frequencies\n",
    "\n",
    "get_word_freq(author_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"This paper explores the design of digital musical instruments (DMIs) for exploratory play. Based on Gaver's principles of ludic design, we examine the ways in which people come to terms with an unfamiliar musical interface. We describe two workshops with the D-Box, a DMI designed to be modified and hacked by the user. The operation of the D-Box is deliberately left ambiguous to encourage users to develop their own meanings and interaction techniques. During the workshops we observed emergent patterns of exploration which revealed a rich process of exploratory play. We discuss our observations in relation to previous literature on appropriation, ambiguity and ludic engagement, and we provide recommendations for the design of playful and exploratory interfaces.\""
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "def get_paper_urls(page_soups):\n",
    "    urls = []\n",
    "    for soup in page_soups:\n",
    "        url = soup.find('a', attrs={'class': 'gsc_vcd_title_link'}).get('href')\n",
    "        urls.append(url)\n",
    "    return urls\n",
    "\n",
    "paper_urls = get_paper_urls(page_soups)\n",
    "\n",
    "df = df_abstracts.assign(real_paper_url=paper_urls)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_paper_soups = get_page_soups(df, 'real_paper_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14\n[]\n[]\n[]\n"
     ]
    }
   ],
   "source": [
    "print(len(real_paper_soups))\n",
    "\n",
    "def get_keywords(paper_soups):\n",
    "    for soup in paper_soups:\n",
    "        keyword_soups = soup.body.findAll(text='Keyword')\n",
    "        print(keyword_soups)\n",
    "\n",
    "get_keywords(real_paper_soups[0:3])"
   ]
  }
 ]
}