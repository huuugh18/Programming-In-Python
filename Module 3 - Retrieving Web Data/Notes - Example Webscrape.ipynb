{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping with BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "### Import BeautifulSoup\n",
    "\n",
    "First off, you will need to import the BeautifulSoup library. BS is not part of the Python standard library (i.e. it needs to be installed separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import beautiful soup library\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with BeautifulSoup, you first require some HTML. HTML can either be loaded from a locally stored file, or it can be \\`requested' from a web server over HTTP.\n",
    "To use the second approach, we will utilise another Python library called `requests`, which is able to make and handle HTTP requests and responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `get` method in the requests library to retrieve an HTTP response object. An HTTP request contains header fields which may give the server some additional information about the request. One of the fields is called, \\`user-agent', and it tells the server what software is making the request on behalf of the user. It may be a good idea to set this header, to try to \\`fool' the server into believing the request is coming via a browser.\n",
    "\n",
    "The response object has a property, `text`, which contains the HTML that was sent in the response.\n",
    "\n",
    "In the following example, the HTML for a web page displaying details about a product on the Tesco website is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a user-agent to be sent with request\n",
    "#headers = {\n",
    "#    \"user-agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\"\n",
    "#}\n",
    "# request a resource from a specific URL. You might want to change this for your chosen website.\n",
    "r  = requests.get(\"https://twitter.com/seanige\")#,headers)\n",
    "\n",
    "# put the text that is returned in the response in a variable\n",
    "data = r.text\n",
    "\n",
    "# look...some HTML has been sent in the response!\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw HTML is not very easy to work with, because it is in a semantic markup format. We need to \\`parse' the HTML (i.e. split it into its component parts), which will make working with it much easier. For that we will create an object which is an instance of the BeautifulSoup class. The object will be a special kind of data structure. It will contain the HTML, but in a format we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the raw HTML into a `soup' object\n",
    "soup = BeautifulSoup(data, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have parsed the HTML, we can call methods of the BeautifulSoup class to access specific elements in the data.\n",
    "\n",
    "### Extract a single element by tag name\n",
    "For example, the `find` method will return the first available element with a specified tag name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<h1>JavaScript is not available.</h1>\n"
     ]
    }
   ],
   "source": [
    "h1 = soup.find(\"h1\")\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all of a certain element by tag name\n",
    "The `find_all` method will return all the elements of a certain type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the th elements with the attributes class:product__info-table\n",
    "#table = soup.find_all(\"table\",attrs={'class':\"product__info-table\"})\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter elements by attribute\n",
    "\n",
    "HTML elements can have attributes. These are key-value pairs defined inside the opening tag. For example, a hyperlink (anchor) tag has an href attribute specifying the URL to link to:\n",
    "\n",
    "        <a href=\"https://twitter.com/seanige\">Dr Sean McGrath</a>\n",
    "        \n",
    "We can be more specific about which elements to retrieve with find all, by including an attribute value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the th elements containing the scope attribute, with the value, `row'\n",
    "#rows = table[0].find_all(\"tr\")\n",
    "#rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter elements by contents\n",
    "We may also decide which elements to extract based on their text contents. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all th elements containing the string, `Data'\n",
    "#datastore = table[0].find_all(\"td\",string=\"Data \")\n",
    "#datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the next sibling element\n",
    "We might want to get at the element next to another element. \n",
    "\n",
    "For example, let's suppose I want the value contained in the `td` element proceding the \\`Salt' `th`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text from the next td element after th\n",
    "#datastore[0].findNext(\"td\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "If you are still feeling a bit lost, you may find this [Webscraping article](https://blog.hartleybrody.com/web-scraping/) by Hartley Brody helpful.\n",
    "\n",
    "The BeautifulSoup documentation can be found here: [BS Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}