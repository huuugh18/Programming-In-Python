{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as NA"
   ]
  },
  {
   "source": [
    "## Pandas NA Handling Methods\n",
    "- `dropna` filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate\n",
    "- `fillna` fill in missing data with some value or use interpolation method such as `fffill` or `bfill`\n",
    "- `isnull` return boolean values indicating which values are missing / NA\n",
    "- `notnull` negation of `isnull`\n",
    "\n",
    "## Filtering out Missing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1.0\n",
       "2    3.5\n",
       "4    7.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data = pd.Series([1, NA, 3.5, NA, 7])\n",
    "data.dropna()\n",
    "\n",
    "#equivalent to data[data.notnull()]\n"
   ]
  },
  {
   "source": [
    "### dataframes more complex\n",
    "may want to drop rows or columns that are all NA or only those containing any NAs  \n",
    "`dropna` by default drops any row containing missing value:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2\n",
       "2  1.113663       NaN  0.837460\n",
       "3  0.252013       NaN  0.266540\n",
       "4 -0.043039 -0.492049 -1.238121\n",
       "5 -1.033481  0.348020  0.698975\n",
       "6 -0.644540 -0.607313  1.055771"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1.113663</td>\n      <td>NaN</td>\n      <td>0.837460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.252013</td>\n      <td>NaN</td>\n      <td>0.266540</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.043039</td>\n      <td>-0.492049</td>\n      <td>-1.238121</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-1.033481</td>\n      <td>0.348020</td>\n      <td>0.698975</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.644540</td>\n      <td>-0.607313</td>\n      <td>1.055771</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA,NA,NA], [NA, 6.5, 3.]])\n",
    "\n",
    "cleaned = data.dropna()\n",
    "\n",
    "#passing `how='all'` wil only drop rows that are all NA\n",
    "cleaned = data.dropna(how='all')\n",
    "\n",
    "#to drop columns in the same way pass axis=1\n",
    "data[4] = NA\n",
    "cleaned = data.dropna(axis=1, how='all')\n",
    "\n",
    "#only want to keep rows containing a certain number of observations\n",
    "#indicate with `thresh` argument\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(7,3))\n",
    "df.iloc[:4, 1] = NA\n",
    "df.iloc[:2, 2] = NA\n",
    "#remove any rows with 2 or more NaN observations\n",
    "df.dropna(thresh=2)"
   ]
  },
  {
   "source": [
    "## Filling in missing data\n",
    "`fillna` is the workhorse function to use  \n",
    "calling with a contast replaces missing values with that value  \n",
    "returns new object but can modify existing object in place with parameter `inplace=True`  \n",
    "`ffill` propogate last valid observation forward to next valid  \n",
    "`bfill` use next valid observation to fill gap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2\n",
       "0 -0.635107 -0.250447  0.324125\n",
       "1 -0.080945 -0.250447  0.324125\n",
       "2  1.113663 -0.250447  0.837460\n",
       "3  0.252013 -0.250447  0.266540\n",
       "4 -0.043039 -0.492049 -1.238121\n",
       "5 -1.033481  0.348020  0.698975\n",
       "6 -0.644540 -0.607313  1.055771"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.635107</td>\n      <td>-0.250447</td>\n      <td>0.324125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.080945</td>\n      <td>-0.250447</td>\n      <td>0.324125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.113663</td>\n      <td>-0.250447</td>\n      <td>0.837460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.252013</td>\n      <td>-0.250447</td>\n      <td>0.266540</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.043039</td>\n      <td>-0.492049</td>\n      <td>-1.238121</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-1.033481</td>\n      <td>0.348020</td>\n      <td>0.698975</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.644540</td>\n      <td>-0.607313</td>\n      <td>1.055771</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# replace all NaN with 0\n",
    "df.fillna(0)\n",
    "\n",
    "#use dict to replace fill value for each column\n",
    "df.fillna({1: 0.5, 2: 0})\n",
    "\n",
    "# pass mean to fill NaN\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "source": [
    "## Data Transformation\n",
    "### Removing Duplicates\n",
    "`data.duplicated()` returns boolean Series indicating whether each row is a duplicate (observed in a previous row) or not  \n",
    "`data.drop_duplicates()` returns a DF where duplicated array is False\n",
    "\n",
    "These methods consider all the columns - can specify a subset column to remove any duplicates of just that column  \n",
    "`data.drop_duplicates(['column_name'])`\n",
    "\n",
    "Passing `keep='last'` will keep the last observed duplicate while the default drops the last and keeps the first  \n",
    "`data.drop_duplicates(['column_one', 'column_two'], keep='last')`\n",
    "\n",
    "### Using a function or mapping\n",
    "Example: want to add a column indicating type of animal that each food came from\n",
    "\n",
    "`map` method on a Series accepts a function or dict like object containing a mapping  \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       pig\n",
       "1       pig\n",
       "2       pig\n",
       "3       cow\n",
       "4       cow\n",
       "5       pig\n",
       "6       cow\n",
       "7       pig\n",
       "8    salmon\n",
       "Name: food, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "## \n",
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "\n",
    "meat_to_animal = {\n",
    "    'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "# problem that some meats capitalized and others not - must convert each val to lowercase\n",
    "lowercased = data['food'].str.lower()\n",
    "\n",
    "# map to column animal\n",
    "data['animal'] = lowercased.map(meat_to_animal)\n",
    "\n",
    "#combined into one function\n",
    "data['food'].map(lambda x: meat_to_animal[x.lower()])\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Replacing Values\n",
    "`replace` provides a simpler and more flexible way to modify a subset of values then the `map` function  \n",
    "Example:  replace all -999 values with nan  \n",
    "`data.replace(-999, np.nan)` \n",
    "\n",
    "Example: Replace multiple values at once  \n",
    "`data.replace([-999, -1000], np.nan)`\n",
    "\n",
    "Different replacement values:  \n",
    "`data.replace([-999, -1000], [np.nan, 0])`\n",
    "\n",
    "Pass argument as dict:  \n",
    "`data.replace({-999: nan, -1000: 0})`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Renaming Axis Indexes\n",
    "like values in series axis labels can be transformed by a function or mapping  \n",
    "can also modify the axes in-place without creating a new data structure\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         one  two  peekaboo  four\n",
       "INDIANA    0    1         2     3\n",
       "COLO       4    5         6     7\n",
       "IDAH       8    9        10    11"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>one</th>\n      <th>two</th>\n      <th>peekaboo</th>\n      <th>four</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>INDIANA</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>COLO</th>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>IDAH</th>\n      <td>8</td>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3,4)), index=['Ohio', 'Colorado', 'Idaho'], columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "#like series, axis indexes have a `map` method\n",
    "transform = lambda x: x[:4].upper()\n",
    "data.index.map(transform)\n",
    "# => Index(['OHIO', 'COLO', 'IDAH'], dtype='object')\n",
    "\n",
    "#assign to index - modifying DF in place\n",
    "data.index = data.index.map(transform)\n",
    "\n",
    "#create transformed version of dataset without modifying original => `rename`\n",
    "data.rename(index=str.title, columns = str.upper)\n",
    "\n",
    "#rename used with a dict\n",
    "data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'})"
   ]
  },
  {
   "source": [
    "## Discretization and Binning\n",
    "Continuous data is often discretized => seperated into 'bins' for analysis  \n",
    "use a `cut` function in pandas  \n",
    "returns a special `Categorical` object  \n",
    "output describes bins computed by `pandas.cut`  -> array of strings indicating bin name  \n",
    "internally contains a `categories` array specifying the distinct category names along with a labeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Youth', 'Youth', 'Youth', 'young adult', 'Youth', ..., 'young adult', 'senior', 'middle aged', 'middle aged', 'young adult']\n",
       "Length: 12\n",
       "Categories (4, object): ['Youth' < 'young adult' < 'middle aged' < 'senior']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "\n",
    "cats = pd.cut(ages, bins)\n",
    "#---> [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]\n",
    "#---> Length: 12\n",
    "#---> Categories (4, interval[int64]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]\n",
    "\n",
    "# labeling for the ages data\n",
    "cats.codes\n",
    "# ===> array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)\n",
    "\n",
    "#get value counts for each bucket\n",
    "pd.value_counts(cats)\n",
    "\n",
    "#pass custom bin names\n",
    "group_names = ['Youth', 'young adult', 'middle aged', 'senior']\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "source": [
    "If you pass an integer number of bins to cut -> compute equal length bins based on min and max values in the data  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.043, 0.27]    6\n",
       "(0.27, 0.5]      6\n",
       "(0.73, 0.95]     5\n",
       "(0.5, 0.73]      3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "data = np.random.rand(20)\n",
    "cats = pd.cut(data, 4, precision=2)"
   ]
  },
  {
   "source": [
    "`qcut` bins the data based on sample quantiles  - `cut` will generally not result in each bin having same number of data points  \n",
    "since `qcut` uses sample quantiles, by definition have roughly equal size bins \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-3.401, -0.682]      250\n",
       "(-0.682, -0.00214]    250\n",
       "(-0.00214, 0.629]     250\n",
       "(0.629, 3.097]        250\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "#normally distributed\n",
    "data = np.random.randn(1000)\n",
    "#cut into quartiles\n",
    "cats = pd.qcut(data, 4)\n",
    "\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "source": [
    "## Detecting and Filtering Outliers\n",
    "\n",
    "largely a matter of applying array operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            0         1         2         3\n",
       "197 -2.572010 -1.270593  0.777687  3.472184\n",
       "345  0.817313 -0.738432 -2.439251 -3.088721\n",
       "502 -0.427646  3.372501  0.321980 -0.325136\n",
       "564  1.699049 -0.293588  3.031306  1.276238\n",
       "706  3.257512  1.044002 -0.436217  0.295035\n",
       "784 -0.956071 -0.242345 -0.424664 -4.099278\n",
       "789 -2.025761  3.037820 -0.376579  1.487068\n",
       "942  1.172454  0.424967  3.328213  0.063023\n",
       "954 -0.698535 -3.294756 -0.009217  0.270611"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>197</th>\n      <td>-2.572010</td>\n      <td>-1.270593</td>\n      <td>0.777687</td>\n      <td>3.472184</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>0.817313</td>\n      <td>-0.738432</td>\n      <td>-2.439251</td>\n      <td>-3.088721</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>-0.427646</td>\n      <td>3.372501</td>\n      <td>0.321980</td>\n      <td>-0.325136</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>1.699049</td>\n      <td>-0.293588</td>\n      <td>3.031306</td>\n      <td>1.276238</td>\n    </tr>\n    <tr>\n      <th>706</th>\n      <td>3.257512</td>\n      <td>1.044002</td>\n      <td>-0.436217</td>\n      <td>0.295035</td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>-0.956071</td>\n      <td>-0.242345</td>\n      <td>-0.424664</td>\n      <td>-4.099278</td>\n    </tr>\n    <tr>\n      <th>789</th>\n      <td>-2.025761</td>\n      <td>3.037820</td>\n      <td>-0.376579</td>\n      <td>1.487068</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>1.172454</td>\n      <td>0.424967</td>\n      <td>3.328213</td>\n      <td>0.063023</td>\n    </tr>\n    <tr>\n      <th>954</th>\n      <td>-0.698535</td>\n      <td>-3.294756</td>\n      <td>-0.009217</td>\n      <td>0.270611</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "data = pd.DataFrame(np.random.randn(1000, 4))\n",
    "\n",
    "#want to find values in one of the columns exceeding 3 in absolute value\n",
    "col = data[2]\n",
    "col[np.abs(col) > 3]\n",
    "\n",
    "#select rows having a value exceeding 3 or -3 use the `any` method on a boolean DF\n",
    "data[(np.abs(data) > 3).any(1)]\n",
    "\n",
    "#cap values outside the intervals of -3 and 3\n",
    "#np.sign(data) gives 1 or -1 depending on pos or neg value\n",
    "data[np.abs(data)>3] = np.sign(data) *3\n",
    "\n",
    " "
   ]
  },
  {
   "source": [
    "## Permutation and Random Samlping\n",
    "\n",
    "Permutation = Randomly Reordering  \n",
    "`numpy.random.permutation` can randomly reorder a Series or rows of DF  \n",
    "call it with the length of the axis you want to permute to produce array of integer indicating new ordering  \n",
    "\n",
    "use sampler array in `iloc` based indexing or the equivalent `take` function  \n",
    "\n",
    "select a random subset without replacement using `sample` method  \n",
    "\n",
    "generate a sample with replacement (allow for repeat choices) => pass `replace = True`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(5*4).reshape((5,4)))\n",
    "sampler = np.random.permutation(5)\n",
    "\n",
    "# use sampler array in `iloc` based indexing or the equivalent `take` function\n",
    "df.take(sampler)\n",
    "\n",
    "#select a random subset without replacement using `sample` method\n",
    "df.sample(n=3)\n",
    "\n",
    "#generate a sample with replacement (allow for repeat choices) => pass `replace = True`\n",
    "choices = pd.Series([5, 7, 9, -4, 2])\n",
    "draws = choices.sample(n=10, replace=True)\n"
   ]
  },
  {
   "source": [
    "## Computing Indicator / Dummy Variables\n",
    "\n",
    "Converting categorical variable into a 'dummy' or 'indicator' matrix  \n",
    "If a col in a DF has `k` distinct values, you would derive a matrix or DF with k cols containing 1's & 0's  \n",
    "pandas has a `get_dummies` function for this \n",
    "\n",
    "might want to add a prefix to the cols in the indicator DF and then merge it with other data  \n",
    "`prefix='key'` parameter \n",
    "\n",
    "if row in DF belongs to multiple categories (pp. 213)\n",
    "- first extract list of unique genres in the dataset\n",
    "    - get array of all unique genres\n",
    "- one way to construct indicator DF is to start with DF of all 0's\n",
    "    - `zero_matrix = np.zeros((len(movies), len(genres)))\n",
    "    - `dummies = pd.DataFrame(zero_matrix, columns = genres)`\n",
    "- now iterate through each movie and set entries in each row of `dummies` to 1\n",
    "    - use the `dummies.columns` to compute the column indices for each genre\n",
    "- then use `.iloc` to set values based on these indices\n",
    "- then combine with movies dataframe\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['b', 'b' , 'a', 'c', 'a', 'b'], 'data1': range(6)})\n",
    "\n",
    "#get dummy vars df\n",
    "pd.get_dummies(df['key'])\n",
    "\n",
    "dummies = pd.get_dummies(df['key'], prefix='key')\n",
    "df_with_dmumy = df[['data1']].join(dummies)\n",
    "# df_with_dmumy"
   ]
  },
  {
   "source": [
    "### RECIPE: combine `get_dummies` with a discretization function like `cut`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]\n",
       "0           0           0           0           0           1\n",
       "1           0           1           0           0           0\n",
       "2           1           0           0           0           0\n",
       "3           0           1           0           0           0\n",
       "4           0           0           1           0           0\n",
       "5           0           0           1           0           0\n",
       "6           0           0           0           0           1\n",
       "7           0           0           0           1           0\n",
       "8           0           0           0           1           0\n",
       "9           0           0           0           1           0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>(0.0, 0.2]</th>\n      <th>(0.2, 0.4]</th>\n      <th>(0.4, 0.6]</th>\n      <th>(0.6, 0.8]</th>\n      <th>(0.8, 1.0]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "values = np.random.rand(10)\n",
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "source": [
    "## String Manipulation (pp. 215)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'a::b:: guido'"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "#split on comma and strip whitespace\n",
    "val = 'a,b, guido'\n",
    "pieces = [x.strip() for x in val.split(',')]\n",
    "    # => ['a', 'b', 'guido']\n",
    "\n",
    "# concactenate with join method\n",
    "'::'.join(pieces) \n",
    "    # => 'a::b::guido'\n",
    "\n",
    "#locating substrings\n",
    "'guido' in val\n",
    "#index raises exception if not found while find returns -1\n",
    "val.index(',')\n",
    "# => 1\n",
    "val.find(':')\n",
    "# => -1\n",
    "\n",
    "#find number of occurances\n",
    "val.count(',')\n",
    "# => 2\n",
    "\n",
    "#replace\n",
    "val.replace(',', '::')\n",
    "# => 'a::b:: guido'\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Regulare Expressions (pp. 217)\n",
    "\n",
    "built in `re` module responsible for applying regex to strings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['     ', '\\t ', '   \\t']"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "import re\n",
    "#split with various whitespace\n",
    "text = 'foo     bar\\t baz   \\tqux'\n",
    "re.split('\\s+', text)\n",
    "# => ['foo', 'bar', 'baz', 'qux']\n",
    "\n",
    "#create a reusable regex func => recommended to save CPU cycles for many uses\n",
    "regex = re.compile('\\s+')\n",
    "regex.split(text)\n",
    "# => ['foo', 'bar', 'baz', 'qux']\n",
    "\n",
    "#list of all matching patterns\n",
    "regex.findall(text)\n",
    "# => ['     ', '\\t ', '   \\t']\n",
    "\n",
    "# match only matches at the beginning of the string\n",
    "# search returns a special match object - tells start and end position of the pattern in the string\n",
    "\n",
    "# sub will return a new string with occurences of the pattern replaced by the new string\n"
   ]
  }
 ]
}